# Story 7.6: LED Visualization Sync via Audio Analysis

**Epic:** Epic 7 - Jam Session Backend Infrastructure (Hybrid: Supabase + WebRTC P2P)
**Status:** üìù READY FOR DEVELOPMENT
**Priority:** üü° MEDIUM
**Complexity:** Medium
**Time Estimate:** 6-8 hours
**Prerequisites:** Story 7.5

---

## User Story

As a **musician in a jam session**,
I want **LED visualizations to sync with the combined audio from all participants**,
So that **the lights reflect what everyone is playing in real-time**.

---

## Story Context

**Existing System Integration:**
- Integrates with: WebRTCAudioService (Story 7.5), WLEDDeviceManager (Epic 6), Web Audio API
- Technology: AnalyserNode, frequency analysis, WLED HTTP API, TypeScript
- Follows pattern: Service layer pattern, audio analysis pipelines
- Touch points: JamSession component, WLED devices, audio streams

**Why This Story:**
LED visualization sync creates immersive visual feedback for jam sessions. By analyzing all participants' audio locally, we achieve the lowest latency (20-50ms) while keeping implementation simple. This approach avoids broadcasting LED data via Supabase, reducing network traffic and latency.

---

## Acceptance Criteria

### Functional Requirements

1. **AudioToLEDService Class Created**
   - File: `src/services/audioToLED.ts`
   - Core methods:
     ```typescript
     class AudioToLEDService {
       private audioContext: AudioContext;
       private analysers: Map<string, AnalyserNode>; // One per peer + local

       analyzeAudio(stream: MediaStream): AnalyserNode
       detectNotes(analyser: AnalyserNode): DetectedNote[]
       mergeVisualizations(notes: DetectedNote[][]): LEDColor[]
       mapNotesToLEDColors(notes: DetectedNote[], colorMode: string): LEDColor[]
     }

     interface DetectedNote {
       frequency: number;
       note: string;        // e.g., "C4", "D#5"
       velocity: number;    // 0-1 (volume)
       timestamp: number;   // Performance.now()
     }

     interface LEDColor {
       r: number; // 0-255
       g: number;
       b: number;
     }
     ```

2. **Analyze All Audio Streams**
   - Create AnalyserNode for local stream:
     ```typescript
     const localAnalyser = audioContext.createAnalyser();
     localAnalyser.fftSize = 2048;
     localStream.connect(localAnalyser);
     ```
   - Create AnalyserNode for each remote peer:
     ```typescript
     remotePeers.forEach(peer => {
       const remoteAnalyser = audioContext.createAnalyser();
       peer.audioStream.connect(remoteAnalyser);
       analysers.set(peer.id, remoteAnalyser);
     });
     ```

3. **Frequency Analysis & Note Detection**
   - Extract frequency data:
     ```typescript
     function detectNotes(analyser: AnalyserNode): DetectedNote[] {
       const dataArray = new Uint8Array(analyser.frequencyBinCount);
       analyser.getByteFrequencyData(dataArray);

       // Peak detection algorithm
       const peaks = findPeaks(dataArray);

       // Convert frequencies to musical notes
       return peaks.map(peak => ({
         frequency: binToFrequency(peak.bin),
         note: frequencyToNote(binToFrequency(peak.bin)),
         velocity: peak.amplitude / 255,
         timestamp: performance.now()
       }));
     }
     ```

4. **Merge Visualizations from All Participants**
   - Combine detected notes from all streams:
     ```typescript
     function mergeVisualizations(allNotes: DetectedNote[][]): LEDColor[] {
       const combinedNotes = allNotes.flat();

       // Sort by velocity (loudest notes first)
       combinedNotes.sort((a, b) => b.velocity - a.velocity);

       // Map to LED colors based on note
       return combinedNotes.map(note => noteToColor(note, colorMode));
     }
     ```

5. **Send LED Data to WLED Devices**
   - Integrate with Epic 6 WLEDDeviceManager:
     ```typescript
     // In JamSession.tsx
     const ledColors = useMemo(() => {
       const localNotes = audioToLED.detectNotes(localAnalyser);
       const remoteNotes = peers.map(peer =>
         audioToLED.detectNotes(analysers.get(peer.id))
       );

       return audioToLED.mergeVisualizations([localNotes, ...remoteNotes]);
     }, [localAnalyser, analysers, peers]);

     return (
       <WLEDDeviceManager
         ledData={ledColors.map(c => rgbToHex(c))}
         layout={isMobile ? 'mobile' : 'desktop'}
         storageKey="wled-jam-session"
       />
     );
     ```

6. **60fps LED Update Loop**
   - Use requestAnimationFrame for smooth updates:
     ```typescript
     function updateLEDVisualization() {
       const ledColors = generateColors();
       sendToWLED(ledColors);
       requestAnimationFrame(updateLEDVisualization);
     }

     requestAnimationFrame(updateLEDVisualization);
     ```

7. **LED Sync Mode Selector**
   - File: `src/components/JamSession/LEDSyncModeSelector.tsx`
   - Modes:
     - **Auto** (default): Try local analysis, fall back if performance issues
     - **Local Analysis**: Each user drives their LEDs from all audio
     - **Off**: Disable LED sync
   - Store mode preference in localStorage

8. **Frequency-to-Note Conversion**
   - File: `src/utils/frequencyToNote.ts`
   - Convert Hz to musical note names:
     ```typescript
     function frequencyToNote(frequency: number): string {
       const A4 = 440; // Hz
       const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];

       const halfSteps = 12 * Math.log2(frequency / A4);
       const noteIndex = Math.round(halfSteps) % 12;
       const octave = Math.floor((Math.round(halfSteps) + 57) / 12);

       return `${noteNames[noteIndex]}${octave}`;
     }
     ```

### Integration Requirements

9. **WLEDDeviceManager Integration**
   - Reuse Epic 6 WLED components
   - Pass LED colors as array of hex strings
   - Maintain existing device management UI

10. **GlobalMusicContext Integration**
    - Use `colorMode` from GlobalMusicContext for note-to-color mapping
    - Respect color mode changes in real-time

11. **Performance Optimization**
    - Maintain 60fps LED refresh rate
    - Throttle analysis if frame drops detected
    - Profile with Chrome DevTools Performance tab

### Quality Requirements

12. **Latency Requirements**
    - **Target:** LEDs update within 50ms of note being played
    - **Acceptable:** LEDs update within 100ms
    - **Measure:** Slow-motion video test (play note, measure LED response)

13. **Sync Accuracy**
    - **Target:** All participants see synchronized LED patterns within 100ms
    - **Test:** Multiple users play simultaneously, verify LED sync

14. **Frame Rate**
    - **Target:** 60fps LED refresh rate maintained
    - **Monitor:** DevTools Performance profiler

---

## Technical Notes

**Integration Approach:**
- Local audio analysis from all streams (lowest latency)
- Web Audio API AnalyserNode for frequency data
- WLED HTTP API for LED control (Epic 6 infrastructure)

**Existing Pattern Reference:**
- Audio analysis similar to LiveAudioVisualizer (Epic 4)
- Service layer pattern similar to WebRTCAudioService
- WLED integration follows Epic 6 patterns

**Key Constraints:**
- Must maintain 60fps LED updates (no dropped frames)
- Audio analysis runs on every frame (performance-critical)
- WLED devices limited to ~200 LEDs per strip (Epic 6 constraint)

**Audio Analysis Details:**
- **FFT Size:** 2048 (good frequency resolution)
- **Frequency Range:** 20Hz-20kHz (human hearing range)
- **Peak Detection:** Find dominant frequencies, convert to notes

---

## Definition of Done

- [ ] `AudioToLEDService` class created and functional
- [ ] Frequency analysis and note detection implemented
- [ ] Merge visualizations from all participants
- [ ] LED color mapping based on detected notes
- [ ] WLED integration working (reuse Epic 6 components)
- [ ] 60fps LED update loop implemented
- [ ] LED sync mode selector created
- [ ] Frequency-to-note conversion utility created
- [ ] Performance profiling shows 60fps maintained
- [ ] Latency <50ms verified (slow-motion video test)
- [ ] Manual testing completed (see Testing Strategy)

---

## Testing Strategy

### Manual Testing (Per CLAUDE.md Guidelines)

**Test 1: Local Audio Analysis**
1. Create session with microphone enabled
2. Play single note (sing or instrument)
3. Verify:
   - ‚úÖ Note detected correctly (e.g., "C4")
   - ‚úÖ LEDs light up corresponding color
   - ‚úÖ Latency <50ms (use slow-motion video)

**Test 2: Multi-User LED Sync**
1. Two users in same session (Alice, Bob)
2. Alice plays note, Bob silent
3. Verify both users' LEDs:
   - ‚úÖ Alice's LEDs show note color
   - ‚úÖ Bob's LEDs show same note color (synced)
4. Alice stops, Bob plays different note
5. Verify:
   - ‚úÖ Both LEDs update to Bob's note color
   - ‚úÖ Sync within 100ms

**Test 3: Combined Audio Visualization**
1. Three users play simultaneously
2. Each plays different note
3. Verify:
   - ‚úÖ LEDs show combined visualization (multiple colors or dominant note)
   - ‚úÖ Loudest note takes priority

**Test 4: 60fps Performance**
1. Open Chrome DevTools ‚Üí Performance tab
2. Record LED visualization for 10 seconds
3. Analyze frame rate:
   - ‚úÖ Maintain 60fps (no dropped frames)
   - ‚úÖ Audio analysis doesn't block main thread

**Test 5: WLED Device Integration**
1. Connect physical WLED device (or use simulator)
2. Play notes, verify:
   - ‚úÖ WLED strip updates correctly
   - ‚úÖ Colors match expected note mapping
   - ‚úÖ No flickering or artifacts

**Test 6: LED Sync Mode Selector**
1. Toggle sync modes (Auto, Local Analysis, Off)
2. Verify:
   - ‚úÖ "Off" disables LED updates
   - ‚úÖ "Local Analysis" forces local mode
   - ‚úÖ Mode preference saved in localStorage

### Verification Checklist

- ‚úÖ LEDs update within 50ms of note being played
- ‚úÖ All participants see synchronized LED patterns (within 100ms)
- ‚úÖ LED visualization reflects combined audio from all participants
- ‚úÖ 60fps LED refresh rate maintained
- ‚úÖ Works with Epic 6 WLEDDeviceManager
- ‚úÖ LED sync works with 2-4 users simultaneously
- ‚úÖ Note detection accurate for musical range (C2-C7)

---

## Risk and Compatibility Check

### Minimal Risk Assessment

**Primary Risk:** Audio analysis performance impact (CPU usage)
**Mitigation:**
- Use efficient peak detection algorithm
- Throttle analysis if frame rate drops below 50fps
- Provide "Off" mode to disable LED sync
- Profile with Chrome DevTools Performance tab

**Secondary Risk:** LED sync inaccuracy due to audio latency
**Mitigation:**
- Use local audio analysis (lowest latency)
- Sync within 100ms is acceptable (imperceptible to humans)
- Visual feedback helps users adjust timing

### Compatibility Verification

- [x] **No breaking changes** - Additive feature (new service)
- [x] **Database changes** - None
- [x] **UI changes** - Additive (LED sync mode selector)
- [x] **Performance impact** - Medium (audio analysis, acceptable)

---

## Scope Validation

- [x] Story can be completed in **6-8 hours** (one focused session)
- [x] Integration approach is clear (Web Audio API + WLED)
- [x] Follows existing patterns (service layer, Epic 6 WLED integration)
- [x] No design work required (reuse Epic 6 UI components)

---

## Deliverables

1. **AudioToLEDService**
   - `src/services/audioToLED.ts` (~250 lines)
   - Audio analysis ‚Üí LED mapping service

2. **Frequency-to-Note Utility**
   - `src/utils/frequencyToNote.ts` (~100 lines)
   - Frequency ‚Üí musical note conversion

3. **Updated JamSession Component**
   - `src/components/JamSession/JamSession.tsx` (modified, ~150 lines added)
   - Audio analysis + WLED integration

4. **LEDSyncModeSelector Component**
   - `src/components/JamSession/LEDSyncModeSelector.tsx` (~80 lines)
   - Sync mode UI

5. **Performance Profiling Document**
   - Measure actual latency and frame rates
   - Document performance characteristics

---

## Next Steps After Story 7.6

Once this story is complete, proceed to:
- **Story 7.7:** State Synchronization (Non-Audio) (2-3 hours)
  - Sync tempo, key, scale, playback control via Supabase

---

## References

- **Epic 7:** `docs/epics/epic-7-jam-session-backend.md`
- **Story 7.5:** `docs/stories/7.5-webrtc-p2p-audio.md`
- **Epic 6:** WLED Device Manager (reuse existing components)
- **Web Audio API:**
  - AnalyserNode: https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode

---

**Story Created:** 2025-10-13
**Story Owner:** Product Manager (John)
**Estimated Completion:** 6-8 hours after start
