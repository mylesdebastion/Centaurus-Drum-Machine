# Story 7.5: WebRTC P2P Audio Streaming

**Epic:** Epic 7 - Jam Session Backend Infrastructure (Hybrid: Supabase + WebRTC P2P)
**Status:** üìù READY FOR DEVELOPMENT
**Priority:** üî¥ CRITICAL
**Complexity:** High
**Time Estimate:** 8-12 hours
**Prerequisites:** Story 7.3

---

## User Story

As a **musician in a jam session**,
I want **to hear other participants' audio in real-time with minimal latency**,
So that **we can play music together synchronously without noticeable delay**.

---

## Story Context

**Existing System Integration:**
- Integrates with: `SupabaseSessionService` (WebRTC signaling), JamSession UI, Web Audio API
- Technology: WebRTC (RTCPeerConnection, MediaStream), Supabase Broadcast, TypeScript
- Follows pattern: Service layer pattern, peer-to-peer mesh topology
- Touch points: JamSession component, microphone permissions, audio playback

**Why This Story is Critical:**
Real-time musical jamming requires <50ms audio latency. Supabase Realtime (50-150ms) is too slow for synchronized playing. WebRTC provides direct peer-to-peer connections with 20-50ms latency, enabling participants to play music together naturally.

---

## Acceptance Criteria

### Functional Requirements

1. **WebRTCAudioService Class Created**
   - File: `src/services/webrtcAudio.ts`
   - Core methods:
     ```typescript
     class WebRTCAudioService {
       private peerConnections: Map<string, RTCPeerConnection>;
       private localStream: MediaStream | null;

       async initializeLocalAudio(): Promise<MediaStream>
       async createPeerConnection(peerId: string): RTCPeerConnection
       async createOffer(peerId: string): Promise<RTCSessionDescription>
       async handleOffer(peerId: string, offer: RTCSessionDescription): Promise<RTCSessionDescription>
       async handleAnswer(peerId: string, answer: RTCSessionDescription): Promise<void>
       async handleIceCandidate(peerId: string, candidate: RTCIceCandidate): Promise<void>

       onRemoteStream(callback: (peerId: string, stream: MediaStream) => void): void
       onConnectionStateChange(callback: (peerId: string, state: string) => void): void
     }
     ```

2. **Supabase Broadcast as WebRTC Signaling Channel**
   - Extend `SupabaseSessionService` to broadcast WebRTC signals:
     ```typescript
     // Send WebRTC signals via Supabase
     channel.send({
       type: 'broadcast',
       event: 'webrtc-signal',
       payload: {
         type: 'offer', // or 'answer', 'ice-candidate'
         targetPeerId: 'user-123',
         data: offer
       }
     });

     // Receive WebRTC signals
     channel.on('broadcast', { event: 'webrtc-signal' }, ({ payload }) => {
       if (payload.targetPeerId === myPeerId) {
         handleWebRTCSignal(payload);
       }
     });
     ```

3. **Local Audio Capture (Microphone/Line-In)**
   - Use `navigator.mediaDevices.getUserMedia()`:
     ```typescript
     const stream = await navigator.mediaDevices.getUserMedia({
       audio: {
         echoCancellation: false, // Important for music
         noiseSuppression: false,  // Important for music
         autoGainControl: false,   // Important for music
         sampleRate: 48000,        // CD quality
         channelCount: 2           // Stereo
       }
     });
     ```
   - Store local stream for adding to peer connections

4. **Full-Mesh P2P Topology**
   - Each user connects directly to every other user:
     ```
     User A ‚Üê‚Üí User B
       ‚Üë  √ó      ‚Üë
     User C ‚Üê‚Üí User D

     2 users = 1 connection
     3 users = 3 connections
     4 users = 6 connections
     ```
   - When new participant joins:
     - Existing users create offers to new participant
     - New participant creates answers back
   - When participant leaves:
     - Close peer connections to that participant

5. **Remote Audio Stream Mixing**
   - Use Web Audio API to mix remote streams:
     ```typescript
     const audioContext = new AudioContext();
     const mixNode = audioContext.createGain();

     remoteStreams.forEach(stream => {
       const source = audioContext.createMediaStreamSource(stream);
       source.connect(mixNode);
     });

     mixNode.connect(audioContext.destination);
     ```

6. **STUN/TURN Server Configuration**
   - Configure ICE servers for NAT traversal:
     ```typescript
     const config: RTCConfiguration = {
       iceServers: [
         { urls: 'stun:stun.l.google.com:19302' }, // Free Google STUN
         { urls: 'stun:stun1.l.google.com:19302' },
         // TURN server (add if P2P fails):
         // { urls: 'turn:turn.example.com', username: 'user', credential: 'pass' }
       ]
     };
     ```

7. **WebRTC Connection State Monitoring**
   - Track ICE connection states: `new`, `checking`, `connected`, `disconnected`, `failed`, `closed`
   - Handle failures:
     - Show warning: "Direct audio connection failed, retrying..."
     - Attempt ICE restart: `peerConnection.restartIce()`
     - Fall back to audio-only if needed

8. **Audio Quality Settings**
   - **Low latency mode** (default):
     - 48kHz sample rate
     - 128kbps stereo bitrate
     - Optimized for real-time
   - **High quality mode** (optional):
     - 48kHz sample rate
     - 256kbps stereo bitrate
     - Slight latency increase

### Integration Requirements

9. **JamSession Component Integration**
   - Initialize WebRTCAudioService after session join
   - Request microphone permissions on session start
   - Create peer connections for each participant
   - Display remote audio streams (auto-play)
   - Clean up on session leave

10. **Microphone Permission Handling**
    - File: `src/components/JamSession/AudioPermissionModal.tsx`
    - Show modal on first audio initialization
    - Clear explanation: "Microphone access is required for jamming"
    - Handle permission denied gracefully

11. **Audio Level Meters**
    - File: `src/components/JamSession/AudioLevelMeter.tsx`
    - Display local audio input levels (visual bars)
    - Display remote audio levels per participant
    - Use AnalyserNode for frequency data

### Quality Requirements

12. **Latency Requirements**
    - **Target:** <50ms audio latency on same network
    - **Acceptable:** <100ms latency on different networks
    - **Measure:** Loopback test (play sound, measure when received)

13. **Connection Success Rate**
    - **Target:** 80%+ P2P connection success rate
    - **TURN Fallback:** ~20% of users need relay mode
    - **Monitor:** ICE connection states

14. **Code Quality**
    - All WebRTC logic encapsulated in service
    - Clear error handling for connection failures
    - TypeScript types for all WebRTC events

---

## Technical Notes

**Integration Approach:**
- WebRTC peer connections managed by WebRTCAudioService
- Supabase Broadcast used for WebRTC signaling (no separate signaling server)
- Local audio stream mixed with remote streams via Web Audio API

**Existing Pattern Reference:**
- Service layer pattern similar to `SupabaseSessionService`
- Modal pattern similar to `UsernameModal`
- Audio handling similar to existing audio engine patterns

**Key Constraints:**
- Microphone permission required (browser prompts user)
- HTTPS required for microphone access (works on localhost for dev)
- Full-mesh topology limits scalability to 4-6 users (acceptable for MVP)

**WebRTC Fundamentals:**
- **STUN:** Discovers public IP address for P2P connection
- **TURN:** Relays audio if direct P2P fails (costs ~$2/month)
- **ICE:** Negotiates best connection path between peers
- **SDP:** Session Description Protocol for offer/answer exchange

---

## Definition of Done

- [ ] `WebRTCAudioService` class created and functional
- [ ] Local audio capture working (microphone input)
- [ ] Remote audio playback working (mixed streams)
- [ ] Full-mesh P2P topology implemented
- [ ] STUN/TURN servers configured
- [ ] WebRTC signaling via Supabase Broadcast
- [ ] Microphone permission modal created
- [ ] Audio level meters implemented
- [ ] Connection state monitoring and error handling
- [ ] Audio latency <50ms on same network (verified)
- [ ] Audio latency <100ms on different networks (verified)
- [ ] P2P connection success rate 80%+ (measured)
- [ ] Manual testing completed (see Testing Strategy)

---

## Testing Strategy

### Manual Testing (Per CLAUDE.md Guidelines)

**Test 1: Local Audio Capture**
1. Create session and grant microphone permission
2. Speak into microphone
3. Verify:
   - ‚úÖ Audio level meter shows input levels
   - ‚úÖ No audio feedback loop (echo cancellation off but safe)
   - ‚úÖ Stereo audio captured

**Test 2: Two-User P2P Connection (Same Network)**
1. Create session on Device A (Alice)
2. Join session on Device B (Bob, same WiFi)
3. Alice speaks into microphone
4. Verify on Device B:
   - ‚úÖ Bob hears Alice's audio
   - ‚úÖ Audio latency <50ms (use stopwatch test)
   - ‚úÖ Audio quality is clear (no artifacts)

**Test 3: Three-User Mesh Topology**
1. Repeat Test 2 with third device (Charlie)
2. All three users speak simultaneously
3. Verify:
   - ‚úÖ Each user hears the other two
   - ‚úÖ Audio mixing works correctly
   - ‚úÖ No audio dropouts or glitches

**Test 4: WebRTC Connection Failure**
1. Block WebRTC connections (use browser extension or network settings)
2. Attempt to join session
3. Verify:
   - ‚úÖ Warning: "Direct audio connection failed"
   - ‚úÖ Session continues without audio
   - ‚úÖ No crashes or errors

**Test 5: Latency Measurement (Loopback Test)**
1. Two devices in same room
2. Device A plays metronome click through speakers
3. Device B's microphone picks up click
4. Device A receives audio back via WebRTC
5. Measure total round-trip latency:
   - ‚úÖ <100ms total latency (50ms each direction)

**Test 6: Different Networks (NAT Traversal)**
1. Device A on WiFi, Device B on mobile hotspot
2. Repeat Test 2
3. Verify:
   - ‚úÖ STUN server establishes P2P connection
   - ‚úÖ Audio latency <100ms
   - ‚úÖ If P2P fails, TURN relay works

### Verification Checklist

- ‚úÖ Audio latency <50ms between two users on same network
- ‚úÖ Audio latency <100ms between users on different networks
- ‚úÖ P2P connection succeeds for 80%+ of user pairs
- ‚úÖ Microphone permission prompt works correctly
- ‚úÖ Audio input levels display correctly
- ‚úÖ Remote audio mixing works with 2-4 users
- ‚úÖ Connection failures handled gracefully

---

## Risk and Compatibility Check

### Critical Risk Assessment

**Primary Risk:** WebRTC P2P connection failures (15-20% of users)
**Mitigation:**
- Use TURN server as fallback relay (Twilio, Metered.ca, or self-hosted)
- Monitor ICE connection state and auto-retry
- Show clear error messages ("Direct audio connection failed, using relay mode")
- Fall back to Supabase-only mode (no audio) if TURN also fails
- Test on challenging networks (mobile hotspots, corporate firewalls)
**Expected Success Rate:** 80-85% with TURN relay (acceptable for MVP)

**Secondary Risk:** Microphone permission denied by user
**Mitigation:**
- Clear permission modal explaining why microphone is needed
- Allow session to continue without audio (participant can still see state)
- Show persistent indicator: "Microphone access required for audio"

**Tertiary Risk:** Audio latency >100ms on poor networks
**Mitigation:**
- Measure and display latency to user
- Warn if latency >100ms: "High latency detected, audio may be delayed"
- Suggest wired connection or better WiFi

### Compatibility Verification

- [x] **No breaking changes** - Additive feature (new service, new audio)
- [x] **Database changes** - None
- [x] **UI changes** - Additive (permission modal, audio meters)
- [x] **Performance impact** - Medium (WebRTC audio processing, acceptable)

---

## Scope Validation

- [x] Story is complex but well-defined (**8-12 hours** estimated)
- [x] Integration approach is clear (WebRTC + Supabase signaling)
- [x] Follows established WebRTC patterns
- [x] Critical path for Epic 7 success (enables real-time jamming)

---

## Deliverables

1. **WebRTCAudioService**
   - `src/services/webrtcAudio.ts` (~350 lines)
   - WebRTC P2P audio streaming service

2. **Updated SupabaseSessionService**
   - `src/services/supabaseSession.ts` (modified, ~50 lines added)
   - WebRTC signaling via Broadcast

3. **Updated JamSession Component**
   - `src/components/JamSession/JamSession.tsx` (modified, ~100 lines added)
   - Audio stream integration

4. **AudioPermissionModal Component**
   - `src/components/JamSession/AudioPermissionModal.tsx` (~50 lines)
   - Microphone permission prompt

5. **AudioLevelMeter Component**
   - `src/components/JamSession/AudioLevelMeter.tsx` (~80 lines)
   - Visual audio input levels

---

## Next Steps After Story 7.5

Once this story is complete, proceed to:
- **Story 7.6:** LED Visualization Sync via Audio Analysis (6-8 hours)
  - Synchronize LED visualizations across participants
  - Local audio analysis for lowest latency

---

## References

- **Epic 7:** `docs/epics/epic-7-jam-session-backend.md`
- **Story 7.3:** `docs/stories/7.3-jam-session-ui-integration.md`
- **WebRTC Docs:**
  - Getting Started: https://webrtc.org/getting-started/overview
  - MDN WebRTC API: https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API
  - STUN/TURN Servers: https://www.twilio.com/docs/stun-turn

---

**Story Created:** 2025-10-13
**Story Owner:** Product Manager (John)
**Estimated Completion:** 8-12 hours after start
