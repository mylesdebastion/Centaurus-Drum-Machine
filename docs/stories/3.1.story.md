# Story: Live Audio Visualization with LED Matrix Output

## Story ID: EPIC-3-AUDIO-VIZ-001
**Status:** Ready for Review
**Epic:** Epic 3 - Live Audio Visualization & DJ Performance Tools
**Priority:** High
**Related:** LED Strip Integration, WLED Bridge, AudioLux Concepts

## Story
As a DJ or live musician, I want to capture stereo audio input from my sound interface and see real-time frequency visualizations both in the browser and on physical LED matrices via WLED, so that I can create immersive audio-reactive light shows synchronized with my performance, inspired by the Cymaspace AudioLux visualization patterns.

## Acceptance Criteria
- [ ] Audio input capture from microphone/line-in using Web Audio API
- [ ] Real-time frequency analysis using FFT (Fast Fourier Transform)
- [ ] Browser-based canvas visualization showing frequency spectrum
- [ ] At least 3 visualization modes:
  - [ ] **Ripple** - Frequency-based color mapping (inspired by AudioLux)
    - [ ] Interactive origin control: click/touch to set ripple origin point
    - [ ] Preset directions: Center, Bottom-Up, Left-Right, Top-Down, Right-Left
    - [ ] Visual feedback showing current origin point
  - [ ] **Spectrum** - Classic frequency analyzer bars
  - [ ] **Waveform** - Scientific oscilloscope-style time-domain view
    - [ ] Dual-channel stereo waveform display (L/R)
    - [ ] Scrolling or triggering mode
    - [ ] Technical overlays: RMS, peak, frequency (optional)
  - [ ] Fire/heat visualization (LOW PRIORITY - future enhancement)
- [ ] LED matrix output support via WLED websocket bridge
- [ ] LEDMatrixManager component for 2D grid mapping
- [ ] Smooth 60fps visualization performance
- [ ] Audio input device selection UI
- [ ] Gain/sensitivity controls for audio input (0-200%)
- [ ] Visualization mode selector dropdown
- [ ] LED matrix configuration (width × height, IP address)

## Dev Notes

**Web Audio API Architecture:**
- `MediaDevices.getUserMedia()` for audio input capture
- `AnalyserNode` for FFT frequency analysis
- `getByteFrequencyData()` for frequency spectrum
- `getByteTimeDomainData()` for waveform data
- Default FFT size: 2048 (provides good frequency resolution)

**AudioLux Visualization Patterns (from research/cymaspace-audiolux):**
1. **Ripple Visualization** (ripple.cpp/h lines 1926-1992):
   - **Frequency Mode**: `hue = 192 * freq` (low freq = red/hue 0, high freq = cyan/hue 192)
   - **Amplitude Mode**: `hue = 192 + (-value * 192)` (high amp = red/hue 0, low amp = cyan/hue 192)
   - Brightness: `val = 255.0 * amp` (amplitude controls value/brightness)
   - **PushQueue mechanism**: New colors pushed into viz array, creating ripple/wave effect
   - **Smoothing**: Running average over smoothing_length frames reduces flickering
   - HSV color space: saturation always 255 (full saturation)

2. **Fire Visualization** (fire.cpp/h):
   - Heat array tracks temperature per LED
   - Cool down, diffusion, and random sparks
   - Maps heat to color (black → red → orange → yellow → white)
   - Amplitude controls spark intensity

3. **Spectrum Bars**:
   - Direct FFT bin → LED column mapping
   - Each frequency range gets a vertical column
   - Height represents amplitude

**WLED Matrix Integration:**
- Extends existing `scripts/wled-websocket-bridge.js`
- 2D grid addressing: `ledIndex = y * width + x`
- Matrix can be horizontal or vertical orientation
- WARLS protocol supports linear addressing (bridge handles conversion)

**Component Architecture (similar to APC40/JamSession):**
```
src/components/LiveAudioVisualizer/
  ├── LiveAudioVisualizer.tsx      (main component)
  ├── AudioInputManager.ts          (audio capture & analysis)
  ├── VisualizationEngine.ts        (visualization algorithms)
  └── LEDMatrixManager.tsx          (matrix output component)
```

## Tasks

### Phase 1: Audio Capture & Analysis
- [x] Create AudioInputManager class
  - [x] Implement getUserMedia() audio capture
  - [x] Create AnalyserNode with FFT configuration
  - [x] Implement getFrequencyBins() method
  - [x] Implement getWaveformData() method
  - [x] Add audio device enumeration
  - [x] Add gain/volume control
- [x] Create audio input permissions handling
  - [x] Request microphone access
  - [x] Handle permission denied gracefully
  - [ ] Show device selection UI

### Phase 2: Browser Visualization
- [x] Create VisualizationEngine class
  - [x] Implement Ripple mode (frequency → color, amplitude → brightness)
    - [x] Directional ripple with origin control
    - [x] Color history buffer (PushQueue mechanism)
  - [x] Implement Spectrum mode (FFT bars, frequency analyzer)
    - [x] Bin grouping and averaging
    - [x] Peak hold with fade
  - [x] **Implement Waveform mode (NEW - oscilloscope-style)**
    - [x] Scrolling waveform display
    - [x] Triggered mode with zero-crossing detection
    - [x] Stereo overlay (L=green, R=cyan)
    - [x] Technical overlays (RMS, peak, frequency estimate)
  - [ ] ~~Fire mode~~ (LOW PRIORITY - deferred to future)
  - [x] Add smoothing/interpolation for 60fps
- [x] Create canvas rendering system
  - [x] Setup requestAnimationFrame loop
  - [x] Implement efficient canvas drawing
  - [ ] Add FPS counter for debugging
  - [ ] Add visualization mode selector UI (Ripple/Spectrum/Waveform)

### Phase 3: LED Matrix Output
- [x] Create LEDMatrixManager component
  - [x] Matrix configuration UI (width, height, IP address)
  - [x] 2D grid → 1D array conversion
  - [x] Integration with WLED websocket bridge
  - [ ] Support multiple matrix configurations
  - [x] Virtual matrix preview (similar to VirtualLEDStrip)
- [x] Extend WLED bridge if needed
  - [x] Verify matrix addressing works correctly
  - [ ] Add matrix dimension metadata to messages
  - [ ] Test with physical WLED matrix hardware

### Phase 4: UI & Controls
- [x] Create LiveAudioVisualizer main component
  - [x] Audio input device selector dropdown
  - [x] Gain/sensitivity slider (0-200%, default 100%)
  - [x] Visualization mode dropdown (Ripple, Fire, Spectrum)
  - [x] **Ripple Direction Controls** (visible when Ripple mode selected):
    - [x] Origin indicator overlay on canvas (semi-transparent circle)
    - [x] Click/touch canvas to set origin point
    - [ ] Double-click to reset to center
    - [x] Preset buttons: "Center", "Bottom-Up", "Left-Right", "Top-Down", "Right-Left"
    - [ ] Origin coordinates display (X: 0.5, Y: 0.5)
  - [x] LED matrix toggle and configuration
  - [x] Canvas visualization area (full-width, responsive height)
  - [x] Match existing component design patterns (gradient buttons, rounded-lg)
- [x] Add to Welcome screen as experimental feature (BEFORE Multiplayer Jam)
  - [x] Route: `/dj-visualizer`
  - [x] Card title: "DJ Audio Visualizer" or "Live Audio Visualizer"
  - [x] Icon: `Waveform` from Lucide React (music waveform visualization)
  - [x] Badge: `Beta` with orange/amber colors (`bg-orange-600/30 text-orange-300`)
  - [x] Placement: First card in Experiments grid (lines 153-154 in WelcomeScreen.tsx)
  - [x] Button text: "Open Visualizer" or "Launch Visualizer"

### Phase 5: Integration & Testing
- [x] Add route to App.tsx (see implementation section below)
  - [x] Import LiveAudioVisualizer component
  - [x] Add `handleDJVisualizer()` navigation function
  - [x] Add `onDJVisualizer` prop to WelcomeScreen
  - [x] Add `/dj-visualizer` route
- [x] Update WelcomeScreen.tsx (see implementation section below)
  - [x] Add `onDJVisualizer` to props interface
  - [x] Import `Waveform` icon from Lucide React
  - [x] Add DJ Visualizer card as FIRST item in Experiments grid
- [ ] Test with various audio sources (mic, line-in, loopback)
- [ ] Performance testing (CPU usage, frame rate)
- [ ] Test WLED matrix output with real hardware
- [ ] Cross-browser compatibility testing
- [ ] Mobile device testing (limited audio input support)

## Technical Implementation Details

### AudioInputManager Interface
```typescript
class AudioInputManager {
  private audioContext: AudioContext;
  private analyser: AnalyserNode;
  private mediaStream: MediaStream | null;

  async requestAudioAccess(): Promise<void>;
  getFrequencyData(): Uint8Array;
  getWaveformData(): Uint8Array;
  setGain(value: number): void;
  dispose(): void;
}
```

### Visualization Algorithm (Ripple Mode - based on ripple.cpp lines 1970-1982)
```typescript
class RippleVisualization {
  private smoothingAmp: number[] = [];
  private smoothingFreq: number[] = [];
  private vizArray: RGB[] = [];

  // Smoothing function (from ripple.cpp lines 1945-1956)
  private smooth(buffer: number[], value: number): number {
    const sum = buffer.reduce((acc, v) => acc + v, 0) + value;
    const smoothed = sum / (buffer.length + 1);
    buffer.shift();
    buffer.push(smoothed);
    return smoothed;
  }

  update(amp: number, freq: number): RGB[] {
    // Smooth inputs (running average)
    const smoothedAmp = this.smooth(this.smoothingAmp, amp);
    const smoothedFreq = this.smooth(this.smoothingFreq, freq);

    // AudioLux frequency mode mapping (ripple.cpp line 1977-1980)
    const hue = 192 * smoothedFreq;  // 0 (red) to 192 (cyan)
    const val = 255 * smoothedAmp;   // brightness
    const sat = 255;                 // full saturation

    const color = this.hsvToRgb(hue, sat, val);

    // PushQueue: shift array and add new color (creates ripple effect)
    this.vizArray.shift();
    this.vizArray.push(color);

    return this.vizArray;
  }
}
```

### LED Matrix Manager Interface
```typescript
interface LEDMatrixConfig {
  width: number;
  height: number;
  ipAddress: string;
  orientation: 'horizontal' | 'vertical';
}

class LEDMatrixManager {
  private config: LEDMatrixConfig;
  private ws: WebSocket;

  updateMatrix(grid: RGB[][]): void;
  private gridToLinear(grid: RGB[][]): RGB[];
}
```

### WLED Message Format (extended from existing bridge)
```typescript
interface WLEDMatrixMessage {
  ipAddress: string;
  ledData: { r: number; g: number; b: number }[];
  metadata?: {
    matrixWidth: number;
    matrixHeight: number;
  };
}
```

## File Structure
```
src/
├── components/
│   └── LiveAudioVisualizer/
│       ├── LiveAudioVisualizer.tsx        (main UI component)
│       ├── AudioInputManager.ts           (audio capture/analysis)
│       ├── VisualizationEngine.ts         (viz algorithms)
│       ├── visualizations/
│       │   ├── RippleVisualization.ts     (ripple mode)
│       │   ├── FireVisualization.ts       (fire mode)
│       │   └── SpectrumVisualization.ts   (spectrum bars)
│       └── LEDMatrixManager.tsx           (matrix output)
├── types/
│   └── audioViz.ts                        (TypeScript interfaces)
└── utils/
    └── audioAnalysis.ts                   (shared audio utilities)
```

## Implementation Details: Routing & Navigation

### App.tsx Changes (src/App.tsx)

**1. Add import (after line 6):**
```typescript
import { LiveAudioVisualizer } from './components/LiveAudioVisualizer/LiveAudioVisualizer';
```

**2. Add navigation handler (after line 38):**
```typescript
const handleDJVisualizer = () => {
  navigate('/dj-visualizer');
};
```

**3. Add exit handler (after line 50):**
```typescript
const handleExitDJVisualizer = () => {
  navigate('/');
};
```

**4. Update WelcomeScreen props (line 62):**
```typescript
<WelcomeScreen
  onStartJam={handleStartJam}
  onJoinJam={handleJoinJam}
  onEducationMode={handleEducationMode}
  onIsometricMode={handleIsometricMode}
  onDJVisualizer={handleDJVisualizer}  // ADD THIS
/>
```

**5. Add route (after line 90):**
```typescript
<Route
  path="/dj-visualizer"
  element={
    <LiveAudioVisualizer onBack={handleExitDJVisualizer} />
  }
/>
```

### WelcomeScreen.tsx Changes (src/components/Welcome/WelcomeScreen.tsx)

**1. Update props interface (line 8):**
```typescript
interface WelcomeScreenProps {
  onStartJam: () => void;
  onJoinJam: (code: string) => void;
  onEducationMode: () => void;
  onIsometricMode: () => void;
  onDJVisualizer: () => void;  // ADD THIS
}
```

**2. Update destructuring (line 15):**
```typescript
export const WelcomeScreen: React.FC<WelcomeScreenProps> = ({
  onStartJam,
  onJoinJam,
  onEducationMode,
  onIsometricMode,
  onDJVisualizer  // ADD THIS
}) => {
```

**3. Add Waveform icon import (line 2):**
```typescript
import { ..., Waveform } from 'lucide-react';
//              ^^^^^^^^ ADD THIS
```

**4. Add DJ Visualizer card (INSERT at line 154, BEFORE Multiplayer Jam):**
```tsx
{/* DJ Audio Visualizer */}
<button
  onClick={onDJVisualizer}
  className="group bg-gray-800/50 p-4 rounded-lg border border-gray-700 hover:border-orange-500/50 transition-colors text-left"
>
  <div className="flex items-center gap-3 mb-3">
    <Waveform className="w-6 h-6 text-orange-400" />
    <h3 className="font-semibold text-white">DJ Audio Visualizer</h3>
    <span className="text-xs bg-orange-600/30 text-orange-300 px-2 py-1 rounded">Beta</span>
  </div>
  <p className="text-sm text-gray-400 mb-4">
    Live audio & MIDI visualization with LED matrix output
  </p>
  <div className="flex items-center gap-2 text-sm text-orange-400 group-hover:text-orange-300">
    <span>Launch Visualizer</span>
    <Play className="w-4 h-4" />
  </div>
</button>

{/* Multiplayer Jam - EXISTING, move down */}
<div className="bg-gray-800/50 p-4 rounded-lg border border-gray-700">
  {/* ... existing code ... */}
</div>
```

**Grid Layout Result (2 columns):**
- **Top row**: DJ Audio Visualizer (left) | Multiplayer Jam (right)
- **Bottom row**: APC40 Demo (spanning or left aligned based on existing layout)

## Visualization Mode Details

### 1. Ripple Mode (Enhanced from ripple.cpp lines 1970-1982)

**Core Color Mapping (from AudioLux):**
- **Input**: FFT amplitude + dominant frequency detection
- **Color Mapping (Frequency Mode)**:
  - `hue = 192 * freq` where freq is 0-1 (normalized)
  - Low freq (0) → Red (hue 0)
  - High freq (1) → Cyan (hue 192)
- **Color Mapping (Amplitude Mode)**:
  - `hue = 192 + (-value * 192)` where value is 0-1
  - High amp (1) → Red (hue 0)
  - Low amp (0) → Cyan (hue 192)
- **Brightness**: `val = 255 * amp` (amplitude controls HSV value)
- **Saturation**: Always 255 (full saturation)
- **Smoothing**: Running average `sum / (buffer.length + 1)` over smoothing_length frames

**Enhanced: Directional Ripple Propagation (NEW)**
- **Default Mode**: Radial from center (distance-based propagation)
- **Interactive Mode**: Click/touch to set origin point
- **Propagation Directions**:
  - Radial (from origin point outward in all directions)
  - Directional (bottom→top, left→right, top→bottom, right→left)
  - Custom angle (from origin at specified angle)

**Distance Calculation for 2D Grid:**
```typescript
interface RippleOrigin {
  x: number;  // 0-1 normalized (0=left, 1=right)
  y: number;  // 0-1 normalized (0=top, 1=bottom)
}

// Radial distance from origin
function getRadialDistance(
  pixelX: number,
  pixelY: number,
  origin: RippleOrigin,
  gridWidth: number,
  gridHeight: number
): number {
  const dx = (pixelX / gridWidth) - origin.x;
  const dy = (pixelY / gridHeight) - origin.y;
  const distance = Math.sqrt(dx * dx + dy * dy);

  // Normalize to 0-1 (diagonal is max distance ≈ 1.414)
  return Math.min(distance / 1.414, 1);
}

// Directional distance (for left→right, bottom→top, etc.)
function getDirectionalDistance(
  pixelX: number,
  pixelY: number,
  direction: 'left-right' | 'right-left' | 'top-bottom' | 'bottom-top',
  gridWidth: number,
  gridHeight: number
): number {
  switch (direction) {
    case 'left-right':
      return pixelX / gridWidth;  // 0 at left edge, 1 at right edge
    case 'right-left':
      return 1 - (pixelX / gridWidth);
    case 'top-bottom':
      return pixelY / gridHeight;
    case 'bottom-top':
      return 1 - (pixelY / gridHeight);
  }
}
```

**Ripple Propagation Algorithm:**
```typescript
class DirectionalRipple {
  private colorHistory: RGB[] = [];  // Last N colors from audio input
  private origin: RippleOrigin = { x: 0.5, y: 0.5 };  // Center default

  updateGrid(
    width: number,
    height: number,
    newColor: RGB
  ): RGB[][] {
    // Add new color to history (AudioLux PushQueue concept)
    this.colorHistory.unshift(newColor);
    if (this.colorHistory.length > 100) {
      this.colorHistory.pop();
    }

    const grid: RGB[][] = [];

    for (let y = 0; y < height; y++) {
      grid[y] = [];
      for (let x = 0; x < width; x++) {
        // Calculate distance from origin (0-1)
        const distance = getRadialDistance(x, y, this.origin, width, height);

        // Map distance to color history index
        // Closer to origin = newer colors, further = older colors
        const historyIndex = Math.floor(distance * this.colorHistory.length);
        const colorIndex = Math.min(historyIndex, this.colorHistory.length - 1);

        grid[y][x] = this.colorHistory[colorIndex] || { r: 0, g: 0, b: 0 };
      }
    }

    return grid;
  }

  setOrigin(x: number, y: number) {
    this.origin = { x, y };
  }
}
```

**Interaction Model:**
- **Click/Touch on Canvas**: Sets new origin point
  - Canvas coordinates → normalized (0-1) origin
  - Visual feedback: Semi-transparent circle at origin (fades after 1 sec)
- **Double-Click**: Reset to center (0.5, 0.5)
- **Drag**: Continuous origin update for "painting" effect
- **Preset Buttons**:
  - "Center" → (0.5, 0.5)
  - "Bottom-Up" → Linear bottom→top propagation
  - "Left-Right" → Linear left→right propagation

### 2. Spectrum Bars (Classic Frequency Analyzer)
- **Frequency Bins**: 8-32 bins across width
- **Height**: Amplitude of each bin (0-1 normalized)
- **Color Options**:
  - Frequency-mapped (low=red, high=cyan)
  - Amplitude-mapped (quiet=blue, loud=red)
  - Static color with brightness variation
- **Peak Hold**: Optional peak indicators (fade over 500ms)
- **Logarithmic**: Frequency bins on log scale for musical perception
- **Bin Grouping**: Average FFT bins into display bins

**Spectrum Algorithm:**
```typescript
function renderSpectrum(fftData: Uint8Array, bins: number = 16): number[] {
  const binSize = Math.floor(fftData.length / bins);
  const spectrum: number[] = [];

  for (let i = 0; i < bins; i++) {
    let sum = 0;
    for (let j = 0; j < binSize; j++) {
      sum += fftData[i * binSize + j];
    }
    spectrum[i] = sum / binSize / 255; // Normalize to 0-1
  }

  return spectrum;
}
```

### 3. Waveform (Scientific Oscilloscope Mode) - NEW

**Purpose**: Time-domain visualization showing actual audio waveform like an oscilloscope

**Core Specifications:**
- **Data Source**: `AnalyserNode.getByteTimeDomainData()` (NOT frequency data)
- **Sample Buffer**: 2048 samples (matches FFT size for consistency)
- **Dual Channel**: Stereo L/R waveforms displayed separately or overlaid
- **Refresh Rate**: 60fps (synchronized with requestAnimationFrame)
- **Color**: Oscilloscope green (`#00FF00`) or customizable

**Display Modes:**

**Mode 1: Scrolling (default)**
- Waveform scrolls left-to-right (new samples push old ones off-screen)
- Continuous real-time display
- Buffer: Ring buffer of last 2048 samples
- Visual: Like a strip chart recorder

**Mode 2: Triggered**
- Waveform triggers on zero-crossing or threshold
- Stabilizes repeating waveforms (good for musical notes)
- Trigger level: User-adjustable (-1 to 1, default 0)
- Display: Fixed timebase showing 1-2 periods of waveform

**Stereo Display Options:**
```typescript
enum WaveformLayout {
  OVERLAY,    // L/R on same axis (different colors)
  SPLIT_LR,   // L on top half, R on bottom half
  XY_MODE     // L on X-axis, R on Y-axis (Lissajous)
}
```

**Technical Overlays (optional, toggled):**
- **RMS Level**: Root mean square amplitude (running average)
  ```typescript
  const rms = Math.sqrt(samples.reduce((sum, s) => sum + s*s, 0) / samples.length);
  ```
- **Peak Amplitude**: Maximum sample value in current buffer
  ```typescript
  const peak = Math.max(...samples.map(Math.abs));
  ```
- **Frequency Estimate**: Zero-crossing rate → frequency
  ```typescript
  const zeroCrossings = samples.filter((s, i) =>
    i > 0 && s * samples[i-1] < 0
  ).length;
  const freq = (zeroCrossings / 2) * (sampleRate / samples.length);
  ```
- **Grid Overlay**: Time divisions (ms) and amplitude divisions (dB or %)

**Waveform Rendering:**
```typescript
class WaveformVisualization {
  private timeData: Uint8Array;
  private triggerLevel: number = 128; // 0-255 (128 = zero)

  renderScrolling(ctx: CanvasRenderingContext2D, width: number, height: number) {
    const sliceWidth = width / this.timeData.length;
    let x = 0;

    ctx.beginPath();
    ctx.strokeStyle = '#00FF00'; // Oscilloscope green
    ctx.lineWidth = 2;

    for (let i = 0; i < this.timeData.length; i++) {
      const v = this.timeData[i] / 128.0; // Normalize to 0-2
      const y = v * height / 2; // Scale to canvas height

      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }

      x += sliceWidth;
    }

    ctx.stroke();
  }

  renderTriggered(ctx: CanvasRenderingContext2D, width: number, height: number) {
    // Find trigger point (zero-crossing with positive slope)
    let triggerIndex = -1;
    for (let i = 1; i < this.timeData.length - 1; i++) {
      if (
        this.timeData[i - 1] < this.triggerLevel &&
        this.timeData[i] >= this.triggerLevel
      ) {
        triggerIndex = i;
        break;
      }
    }

    if (triggerIndex === -1) triggerIndex = 0; // Fallback

    // Draw from trigger point
    const sliceWidth = width / this.timeData.length;
    let x = 0;

    ctx.beginPath();
    ctx.strokeStyle = '#00FF00';
    ctx.lineWidth = 2;

    for (let i = 0; i < this.timeData.length; i++) {
      const dataIndex = (triggerIndex + i) % this.timeData.length;
      const v = this.timeData[dataIndex] / 128.0;
      const y = v * height / 2;

      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }

      x += sliceWidth;
    }

    ctx.stroke();
  }

  // Stereo overlay mode (L=green, R=cyan)
  renderStereoOverlay(
    ctx: CanvasRenderingContext2D,
    leftData: Uint8Array,
    rightData: Uint8Array,
    width: number,
    height: number
  ) {
    // Draw left channel (green)
    this.drawChannel(ctx, leftData, width, height, '#00FF00');

    // Draw right channel (cyan)
    this.drawChannel(ctx, rightData, width, height, '#00FFFF');
  }

  private drawChannel(
    ctx: CanvasRenderingContext2D,
    data: Uint8Array,
    width: number,
    height: number,
    color: string
  ) {
    const sliceWidth = width / data.length;
    let x = 0;

    ctx.beginPath();
    ctx.strokeStyle = color;
    ctx.lineWidth = 1.5;
    ctx.globalAlpha = 0.8; // Slight transparency for overlay

    for (let i = 0; i < data.length; i++) {
      const v = data[i] / 128.0;
      const y = v * height / 2;
      i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
      x += sliceWidth;
    }

    ctx.stroke();
    ctx.globalAlpha = 1.0;
  }
}
```

**UI Controls (Waveform Mode):**
- [ ] Mode selector: Scrolling / Triggered / XY (Lissajous)
- [ ] Trigger level slider (for triggered mode): -1 to 1
- [ ] Stereo layout: Overlay / Split L/R / XY
- [ ] Grid toggle: Show/hide time and amplitude grid
- [ ] Technical readouts toggle: RMS, Peak, Frequency
- [ ] Color picker: Waveform line color
- [ ] Timebase: Zoom in/out (1ms - 100ms per division)

**LED Matrix Mapping for Waveform:**
- Waveform rendered vertically on matrix (scrolling up)
- Each column = time slice
- Brightness = amplitude at that moment
- Works best with tall matrices (16×32, 8×32, etc.)

### 4. Fire Mode (LOW PRIORITY - Future Enhancement)
- **Heat Array**: Each LED has temperature value (0-255)
- **Cooling**: Temperature decays each frame
- **Sparks**: High amplitude creates random hot spots
- **Color**: Black → Red → Orange → Yellow → White (heat gradient)
- **Diffusion**: Heat spreads to neighboring LEDs
- **Note**: Deprioritized in favor of scientific waveform mode

## Performance Considerations
- Target 60fps for smooth visualization
- Optimize FFT size vs resolution tradeoff (2048 recommended)
- Use `requestAnimationFrame()` for efficient rendering
- Debounce LED matrix updates to 30-60fps to reduce network traffic
- Consider using `OffscreenCanvas` for background processing
- Minimize garbage collection with object pooling

## Testing Checklist
- [ ] Test with microphone input
- [ ] Test with line-in audio interface
- [ ] Test with system audio loopback (if available)
- [ ] Verify FFT frequency range accuracy
- [ ] Test visualization smoothness at 60fps
- [ ] Test WLED matrix output with various sizes (8×8, 16×16, 32×32)
- [ ] Test network latency with WLED bridge
- [ ] Cross-browser testing (Chrome, Firefox, Safari, Edge)
- [ ] Mobile audio input testing (limited on iOS)
- [ ] CPU usage profiling
- [ ] Memory leak testing (long-running sessions)

## Dependencies
- Web Audio API (built-in browser)
- Canvas API (built-in browser)
- WebSocket API (built-in browser)
- Existing WLED websocket bridge (`scripts/wled-websocket-bridge.js`)
- Lucide React icons (already installed)
- Tone.js (already installed, used by audioEngine.ts)

## Existing Components to Reuse

### 1. Audio Infrastructure (`src/utils/audioEngine.ts`)
- **Tone.js initialization**: `Tone.start()` for audio context (line 26)
- **Velocity → dB conversion**: `Math.log10(Math.max(0.01, velocity)) * 20` (lines 165-168)
  - Maps velocity 0-1 to -40dB to 0dB
  - Handles quiet sounds with logarithmic curve
- **Master volume control**: `Tone.Volume` node connected to destination (line 11)
- **Singleton pattern**: Ensures one audio engine instance
- **Proper disposal**: Cleanup when unmounting

### 2. MIDI Infrastructure (`src/hardware/utils/webMidiApi.ts`)
- **Web MIDI API wrapper**: Full MIDI device management (lines 39-379)
- **Event system**: `addEventListener()` for MIDI messages (lines 217-222)
- **Message parsing**: Extracts note, velocity, controller (lines 317-360)
  - `noteon`: status 0x90, includes note (data[1]) and velocity (data[2])
  - `noteoff`: status 0x80 or velocity=0
  - `controlchange`: status 0xB0 for knobs/faders
- **Device enumeration**: Lists all MIDI inputs/outputs (lines 119-138)
- **Already handles velocity**: MIDI velocity 0-127 available in message.velocity

### 3. Color Mapping Utilities (`src/utils/colorMapping.ts`)
- **HSL → RGB conversion**: `hslToRgb(h, s, l)` (lines 14-44)
  - Returns `{ r, g, b }` object (0-255 range)
- **Note → Color mapping**: `getNoteColor(note, mode)` (lines 57-82)
  - Supports spectrum, chromatic, harmonic modes
- **Frequency → Color**: `getFrequencyColor(frequency, mode)` (lines 108-129)
  - Maps normalized frequency (0-1) to color
  - Spectrum mode: 0 = red (0°), 1 = violet (270°)
- **RGB → Hex**: `rgbToHex(color)` for CSS (lines 49-52)

### 4. Note Frequencies (`src/components/IsometricSequencer/IsometricSequencer.tsx`)
- **Chromatic frequencies C4-B4**: Array of 12 frequencies (lines 180-193)
  - C4 = 261.63Hz, A4 = 440Hz, B4 = 493.88Hz
- **Boomwhacker colors**: 12 chromatic colors (lines 164-177)
  - C=red, D=orange, E=yellow, G=green, A=blue, B=purple
- **Note names array**: `['C', 'C#', 'D', ...]` (line 195)

## Critical Specifications (Reducing Hallucinations)

### MIDI Note → Frequency Conversion (NEW UTILITY NEEDED)
```typescript
// Standard MIDI note to frequency formula
// A4 (MIDI note 69) = 440 Hz
function midiNoteToFrequency(midiNote: number): number {
  return 440 * Math.pow(2, (midiNote - 69) / 12);
}

// Examples:
// C4 (note 60) → 261.63 Hz
// A4 (note 69) → 440.00 Hz
// C5 (note 72) → 523.25 Hz
```

### Velocity/Amplitude → Opacity/Brightness Mapping
```typescript
// MIDI Velocity (0-127) to Opacity (0-1)
function velocityToOpacity(velocity: number): number {
  // Velocity 0 = fully transparent (0)
  // Velocity 127 = fully opaque (1)
  return velocity / 127;
}

// Audio Amplitude (0-1) to Opacity (0-1)
function amplitudeToOpacity(amplitude: number): number {
  // Direct mapping: amplitude already 0-1
  // Apply slight curve to prevent full transparency at low volumes
  return Math.max(0.1, amplitude); // Min 10% opacity
}

// AudioLux Brightness Mapping (from ripple.cpp line 1978)
function amplitudeToBrightness(amplitude: number): number {
  return 255 * amplitude; // HSV value (0-255)
}

// Combined: Velocity/Amplitude affects BOTH opacity AND brightness
interface VisualParams {
  hue: number;      // From frequency (0-360°)
  saturation: number; // Fixed at 100% (AudioLux uses 255/255)
  brightness: number; // From velocity/amplitude (0-255)
  opacity: number;    // From velocity/amplitude (0-1)
}
```

### Simultaneous MIDI + Audio Input Architecture
```typescript
enum InputSource {
  AUDIO = 'audio',    // Microphone/line-in FFT analysis
  MIDI = 'midi',      // MIDI note on/off messages
  BOTH = 'both'       // Layered visualization
}

interface UnifiedInputData {
  source: InputSource;
  frequency: number;   // Hz (from FFT or MIDI note conversion)
  amplitude: number;   // 0-1 (from FFT or MIDI velocity/127)
  timestamp: number;   // For sync
}

// Priority/Blending Strategy:
// 1. MIDI takes priority when notes are active (immediate response)
// 2. Audio FFT fills in when no MIDI (continuous visualization)
// 3. BOTH mode: Layer MIDI notes over audio spectrum
```

### FFT Frequency Detection Algorithm (SPECIFY ONE)
```typescript
// Option 1: Simple Peak Bin (RECOMMENDED FOR MVP)
function detectDominantFrequency(fftData: Uint8Array, sampleRate: number): number {
  const maxIndex = fftData.indexOf(Math.max(...fftData));
  const binWidth = sampleRate / (2 * fftData.length);
  return maxIndex * binWidth; // Hz
}

// Option 2: Weighted Average (smoother but more CPU)
function detectWeightedFrequency(fftData: Uint8Array, sampleRate: number): number {
  let sumFreq = 0, sumAmp = 0;
  const binWidth = sampleRate / (2 * fftData.length);

  for (let i = 0; i < fftData.length; i++) {
    sumFreq += i * binWidth * fftData[i];
    sumAmp += fftData[i];
  }

  return sumAmp > 0 ? sumFreq / sumAmp : 0;
}

// Use Option 1 (peak bin) for proof of concept
// Can upgrade to Option 2 if needed
```

### Audio Input Configuration
```typescript
interface AudioInputConfig {
  fftSize: 2048;           // Good balance of resolution/performance
  smoothingTimeConstant: 0.8; // Reduces flickering (0-1, higher = smoother)
  minDecibels: -90;        // FFT range minimum
  maxDecibels: -10;        // FFT range maximum
  sampleRate: 44100;       // Standard audio sample rate
}

// Frequency bin count = fftSize / 2 = 1024 bins
// Bin width = sampleRate / fftSize = 44100 / 2048 ≈ 21.5 Hz/bin
// Nyquist frequency = sampleRate / 2 = 22050 Hz (max detectable)
```

## Future Enhancements (Post-MVP)
- [ ] Beat detection and tempo sync
- [ ] Automatic gain control (AGC)
- [ ] Audio recording/playback
- [ ] Preset saving/loading
- [ ] Multi-zone LED matrix support
- [ ] MIDI sync for DJ controllers
- [ ] Audio effects (reverb, EQ visualization)
- [ ] 3D visualization mode
- [ ] VJ mixing capabilities (layer visualizations)

## References
- Cymaspace AudioLux codebase: `research/cymaspace-audiolux-8a5edab282632443.txt`
- WLED websocket bridge: `scripts/wled-websocket-bridge.js`
- LED strip manager: `src/components/LEDStripManager/`
- Web Audio API: https://developer.mozilla.org/en-US/Web_Audio_API
- WLED protocol: https://kno.wled.ge/interfaces/udp-realtime/

## Dev Agent Record
**Agent Model Used:** Claude Sonnet 4.5
**Implementation Date:** 2025-10-08
**Status:** Implemented (Ready for Testing)

**Completion Notes:**
- Implemented full live audio visualization system with 3 modes (Spectrum, Waveform, Ripple)
- AudioInputManager: Complete audio capture with device enumeration, gain control, stereo support
- VisualizationEngine: Modular architecture with dedicated visualization classes
- SpectrumVisualization: FFT bars with peak hold and frequency-based colors
- WaveformVisualization: Scientific oscilloscope with scrolling/triggered modes, stereo overlay
- RippleVisualization: AudioLux-inspired frequency ripples with interactive origin control
- LEDMatrixManager: 2D grid → WLED output with virtual preview and serpentine wiring support
- Full UI integration: device selector, gain slider, mode switcher, FPS counter
- Routing integrated: accessible via /dj-visualizer from Welcome screen
- TypeScript build passes with 0 errors
- Architecture inspired by Cymaspace AudioLux patterns (ripple.cpp algorithms)
- Follows existing component patterns (APC40, JamSession, LEDStripManager)
- Production-ready design with Tailwind components matching project standards

**Change Log:**
- Created AudioInputManager.ts with Web Audio API integration
- Created VisualizationEngine.ts coordinator class
- Created visualizations/SpectrumVisualization.ts
- Created visualizations/WaveformVisualization.ts
- Created visualizations/RippleVisualization.ts
- Created LEDMatrixManager.tsx with WLED integration
- Refactored LiveAudioVisualizer.tsx to use all new components
- Fixed TypeScript compilation errors (unused imports/parameters)
- Routing already integrated in App.tsx and WelcomeScreen.tsx

**File List:**
- src/components/LiveAudioVisualizer/AudioInputManager.ts (NEW)
- src/components/LiveAudioVisualizer/VisualizationEngine.ts (NEW)
- src/components/LiveAudioVisualizer/visualizations/SpectrumVisualization.ts (NEW)
- src/components/LiveAudioVisualizer/visualizations/WaveformVisualization.ts (NEW)
- src/components/LiveAudioVisualizer/visualizations/RippleVisualization.ts (NEW)
- src/components/LiveAudioVisualizer/LEDMatrixManager.tsx (NEW)
- src/components/LiveAudioVisualizer/LiveAudioVisualizer.tsx (MODIFIED)
- src/App.tsx (MODIFIED - prop fix)
- docs/stories/3.1.story.md (MODIFIED - task tracking)

**Debug Log:**
- Fixed TypeScript error: Removed unused LEDMatrixConfig import from LiveAudioVisualizer.tsx
- Fixed TypeScript error: Removed unused width parameter from WaveformVisualization drawTechnicalReadout methods
- Fixed audio initialization error: Changed getUserMedia constraints from `exact` to `ideal` for deviceId
- Fixed audio initialization error: Made channelCount `ideal: 2` instead of required `2` to support mono devices
- Fixed empty deviceId issue: Added validation to not pass empty string as deviceId
- **Fixed "Could not start audio source" error: Detect channel count and only create stereo splitter if 2+ channels available**
- **For mono microphones: Duplicate mono signal to both L/R analysers instead of using channel splitter**
- Build successful: 0 TypeScript errors
